Spark Command: /usr/local/Cellar/openjdk/15.0.1/libexec/openjdk.jdk/Contents/Home/bin/java -cp /Users/apabook/spark/conf/:/Users/apabook/spark/jars/* -Xmx1g org.apache.spark.deploy.history.HistoryServer -n
========================================
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
20/12/09 23:00:09 INFO HistoryServer: Started daemon with process name: 16997@MacBook-Pro-de-Carlos.local
20/12/09 23:00:09 INFO SignalUtils: Registered signal handler for TERM
20/12/09 23:00:09 INFO SignalUtils: Registered signal handler for HUP
20/12/09 23:00:09 INFO SignalUtils: Registered signal handler for INT

Usage: HistoryServer [options]

Options:
  --properties-file FILE      Path to a custom Spark properties file.
                              Default is conf/spark-defaults.conf.

Configuration options can be set by setting the corresponding JVM system property.
History Server options are always available; additional options depend on the provider.

History Server options:

  spark.history.ui.port              Port where server will listen for connections
                                     (default 18080)
  spark.history.acls.enable          Whether to enable view acls for all applications
                                     (default false)
  spark.history.provider             Name of history provider class (defaults to
                                     file system-based provider)
  spark.history.retainedApplications Max number of application UIs to keep loaded in memory
                                     (default 50)
FsHistoryProvider options:

  spark.history.fs.logDirectory      Directory where app logs are stored
                                     (default: file:/tmp/spark-events)
  spark.history.fs.update.interval   How often to reload log data from storage
                                     (in seconds, default: 10)

